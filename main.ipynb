{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Original Data Set and Creating Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# original_df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# # Selecting only ARTICLE_ID and SECTION_TEXT columns\n",
    "# subset_df = original_df[['ARTICLE_ID', 'SECTION_TEXT']]\n",
    "\n",
    "# # Taking a subset of 2000 rows from the original dataset\n",
    "# subset_df = subset_df.head(2000)\n",
    "\n",
    "# subset_df.to_csv(\"subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and Pre Processing Data from Sample (subset.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import OrderedDict\n",
    "\n",
    "subset_df = pd.read_csv(\"subset.csv\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Tokenizing the text\n",
    "    words = word_tokenize(text)\n",
    "    # Removing stopwords and punctuation, and converting to lowercase\n",
    "    filtered_words = [word.lower() for word in words if word.isalnum()\n",
    "                      and word.lower() not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "# Dictionary to store unique words with index\n",
    "corpus = OrderedDict()\n",
    "\n",
    "# Iterate through the rows to build the corpus\n",
    "for index, row in subset_df.iterrows():\n",
    "    article_text = row['SECTION_TEXT']\n",
    "    preprocessed_words = preprocess_text(article_text)\n",
    "    # Adding preprocessed words to the corpus\n",
    "    for word in preprocessed_words:\n",
    "        if word not in corpus:\n",
    "            corpus[word] = len(corpus)  # Assign index if the word is new\n",
    "\n",
    "\n",
    "print(\"Corpus with assigned indices:\")\n",
    "for idx, word in corpus.items():\n",
    "    print(f\"({word}, '{idx}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store TF for each word in the corpus\n",
    "term_frequency = {index: 0 for index in corpus.values()}\n",
    "\n",
    "# Iterating through the rows to calculate term frequency\n",
    "for index, row in subset_df.iterrows():\n",
    "    article_text = row['SECTION_TEXT']\n",
    "    preprocessed_words = preprocess_text(article_text)\n",
    "\n",
    "    # Dictionary to store TF in articles\n",
    "    tf_article = {index: 0 for index in corpus.values()}\n",
    "\n",
    "    # TF for each word in the article\n",
    "    for word in preprocessed_words:\n",
    "        if word in corpus:\n",
    "            index = corpus[word]\n",
    "            tf_article[index] += 1\n",
    "            term_frequency[index] += 1\n",
    "\n",
    "    # Remove words with 0 frequency\n",
    "    non_zero_tf_article = {word: tf for word,\n",
    "                           tf in tf_article.items() if tf > 0}\n",
    "    print(f\"Article {row['ARTICLE_ID']} TF: {non_zero_tf_article}\")\n",
    "\n",
    "term_frequency = {index: tf for index, tf in term_frequency.items() if tf > 0}\n",
    "\n",
    "\n",
    "print(\"\\nNon-zero Term Frequencies:\")\n",
    "print(term_frequency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
